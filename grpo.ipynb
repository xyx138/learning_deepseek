{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import trl\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0+cu121'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "按照如下格式生成：\n",
    "<think>\n",
    "...\n",
    "</think>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "def process_data(data):\n",
    "    data = data.map(lambda x: {\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': x['question_zh-cn']}\n",
    "        ],\n",
    "        'answer': x['answer_only']\n",
    "    }) \n",
    "    return data\n",
    "def extract_answer(text):\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "def mark_num(text):\n",
    "    reward = 0\n",
    "    if text.count(\"<think>\\n\") == 1:\n",
    "        reward += 0.125\n",
    "        \n",
    "    if text.count(\"</think>\\n\") == 1:\n",
    "        reward += 0.125\n",
    "        \n",
    "    if text.count(\"<answer>\\n\") == 1:\n",
    "        reward += 0.125\n",
    "        \n",
    "    if text.count(\"</answer>\\n\") == 1:\n",
    "        reward += 0.125\n",
    "    return reward\n",
    "\n",
    "# 生成答案是否正确的奖励\n",
    "def correctness_reward(prompts, completions, answer, **kwargs):\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    extracted_responses = [extract_answer(r) for r in responses]\n",
    "    print(f\"问题:\\n{prompts[0][-1]['content']}\", f\"\\n答案:\\n{answer[0]}\", f\"\\n模型输出:\\n{responses[0]}\", f\"\\n提取后的答案:\\n{extracted_responses[0]}\")\n",
    "    return [2.0 if response == str(ans) else 0.0 for response, ans in zip(extracted_responses, answer)]\n",
    "# 生成答案是否是数字的奖励（单纯依赖结果是否正确进行奖励，条件很苛刻，会导致奖励比较稀疏，模型难以收敛，所以加上答案是否是数字的奖励，虽然答案错误，但是至少生成的是数字（对于数学问题），也要给予适当奖励）\n",
    "def digit_reward(completions, **kwargs):\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    extracted_responses = [extract_answer(r) for r in responses]\n",
    "    return [0.5 if response.isdigit() else 0.0 for response in extracted_responses]\n",
    "\n",
    "# 格式奖励\n",
    "def hard_format_reward(completions, **kwargs):\n",
    "    pattern = r\"^<think>\\n.*?n</think>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, response) for response in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "# 格式奖励\n",
    "def soft_format_reward(completions, **kwargs):\n",
    "    pattern = r\"<think>.*?</think>\\s*<answer>.*?</answer>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, response) for response in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "# 标记奖励（改善格式奖励稀疏问题）\n",
    "def mark_reward(completions, **kwargs):\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    return [mark_num(response) for response in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = \"/root/data/.cache/huggingface_hub\"\n",
    "os.environ['HF_ENDPOINT'] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME=/root/data/.cache/huggingface_hub\n"
     ]
    }
   ],
   "source": [
    "!env | grep HF_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"/root/data/.cache/huggingface_hub/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('/root/data/.cache/huggingface_hub/hub/datasets--swulling--gsm8k_chinese/snapshots/961c39528fe28d424672b44e768d72d5bf089ca2')\n",
    "data = process_data(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'answer': 72,\n",
       " 'question_zh-cn': '纳塔利娅在 4 月份向 48 个朋友出售了视频片段，然后在 5 月份售出了一半的视频片段。娜塔莉亚在四月和五月总共卖出了多少个视频？',\n",
       " 'answer_only': 72,\n",
       " 'prompt': [{'content': '\\n按照如下格式生成：\\n<think>\\n...\\n</think>\\n<answer>\\n...\\n</answer>\\n',\n",
       "   'role': 'system'},\n",
       "  {'content': '纳塔利娅在 4 月份向 48 个朋友出售了视频片段，然后在 5 月份售出了一半的视频片段。娜塔莉亚在四月和五月总共卖出了多少个视频？',\n",
       "   'role': 'user'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = GRPOConfig(\n",
    "        output_dir='./output',\n",
    "        learning_rate=5e-6,\n",
    "        adam_beta1 = 0.9,\n",
    "        adam_beta2 = 0.99,\n",
    "        weight_decay = 0.1,\n",
    "        warmup_ratio = 0.1,\n",
    "        lr_scheduler_type='cosine',\n",
    "        logging_steps=1,\n",
    "        bf16=True,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_generations=8,\n",
    "        max_prompt_length=256,\n",
    "        max_completion_length=200,\n",
    "        num_train_epochs=1,\n",
    "        save_steps=100,\n",
    "        max_grad_norm=0.1,\n",
    "        log_on_each_node=False,\n",
    "        use_vllm=False,\n",
    "        report_to=\"tensorboard\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.7, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs=[\n",
    "        mark_reward,\n",
    "        soft_format_reward,\n",
    "        hard_format_reward,\n",
    "        digit_reward,\n",
    "        correctness_reward\n",
    "        ],\n",
    "    args = training_args,\n",
    "    train_dataset=data\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题:\n",
      "艾哈迈德和艾米丽正在进行一场比赛，看谁能获得班上最好的成绩。共有 9 项作业，艾哈迈德在课堂上得了 91 分。 Emily 的得分为 92。最终作业的价值与所有其他作业的价值相同。艾米丽的期末作业得了 90 分。如果所有成绩均为整数，艾哈迈德击败艾米丽所需的最低成绩是多少？ \n",
      "答案:\n",
      "100 \n",
      "模型输出:\n",
      "让我们首先计算所有作业的整体价值，并根据这些价值得出艾哈迈德和艾米丽在各个部分的表现。由于所有作业的价值相同，我们可以将它们视为一个数组，然后找到这个数组中，与艾哈迈德和艾米丽在各个部分得分相等的部分。接着，我们需要找出艾哈迈德得分低于这个值的那一项作业。\n",
      "\n",
      "以下是具体步骤：\n",
      "\n",
      "1. **计算总和**：艾哈迈德在所有作业上的得分加上艾米丽在所有作业上的得分，也就是183分（91+92+90+91）。\n",
      "2. **确定总和中与艾哈迈德和艾米丽得分相等的部分**：我们需要找到一个部分，使得这个部分的总分与艾哈迈德和艾米丽得分相等。\n",
      "   - 相等部分的得分是170分（183/2）。\n",
      "3. **确定其他作业 \n",
      "提取后的答案:\n",
      "让我们首先计算所有作业的整体价值，并根据这些价值得出艾哈迈德和艾米丽在各个部分的表现。由于所有作业的价值相同，我们可以将它们视为一个数组，然后找到这个数组中，与艾哈迈德和艾米丽在各个部分得分相等的部分。接着，我们需要找出艾哈迈德得分低于这个值的那一项作业。\n",
      "\n",
      "以下是具体步骤：\n",
      "\n",
      "1. **计算总和**：艾哈迈德在所有作业上的得分加上艾米丽在所有作业上的得分，也就是183分（91+92+90+91）。\n",
      "2. **确定总和中与艾哈迈德和艾米丽得分相等的部分**：我们需要找到一个部分，使得这个部分的总分与艾哈迈德和艾米丽得分相等。\n",
      "   - 相等部分的得分是170分（183/2）。\n",
      "3. **确定其他作业\n",
      "问题:\n",
      "水箱上的水表显示水箱已充满 1/3 的水。为了填充水箱，添加了 16 加仑的水。水箱满后可容纳多少加仑的水？ \n",
      "答案:\n",
      "24 \n",
      "模型输出:\n",
      "为了解决这个问题，我们首先需要理解水箱已有的水量和添加的水量。\n",
      "\n",
      "1. 已有的水量是1/3水箱容量的水量是 \\( \\frac{1}{3} \\times \\text{水箱容量} \\)。\n",
      "2. 添加的水量是16加仑。\n",
      "\n",
      "因此，我们可以通过以下公式计算水箱满后可容纳的水量：\n",
      "\n",
      "\\[ \\text{满后水量} = \\text{已有的水量} + \\text{添加的水量} \\]\n",
      "\\[ \\text{满后水量} = \\frac{1}{3} \\times \\text{水箱容量} + 16 \\]\n",
      "\n",
      "我们只需要代入已有的水量（1/3水箱容量的水量）来计算满后可容纳的水量。\n",
      "\n",
      "让我们逐步计算：\n",
      "\n",
      "首先，我们计算已有的水量：\\[ \\text{已有的水量} = \\frac{1}{3} \\times \\text{水箱容量 \n",
      "提取后的答案:\n",
      "为了解决这个问题，我们首先需要理解水箱已有的水量和添加的水量。\n",
      "\n",
      "1. 已有的水量是1/3水箱容量的水量是 \\( \\frac{1}{3} \\times \\text{水箱容量} \\)。\n",
      "2. 添加的水量是16加仑。\n",
      "\n",
      "因此，我们可以通过以下公式计算水箱满后可容纳的水量：\n",
      "\n",
      "\\[ \\text{满后水量} = \\text{已有的水量} + \\text{添加的水量} \\]\n",
      "\\[ \\text{满后水量} = \\frac{1}{3} \\times \\text{水箱容量} + 16 \\]\n",
      "\n",
      "我们只需要代入已有的水量（1/3水箱容量的水量）来计算满后可容纳的水量。\n",
      "\n",
      "让我们逐步计算：\n",
      "\n",
      "首先，我们计算已有的水量：\\[ \\text{已有的水量} = \\frac{1}{3} \\times \\text{水箱容量\n",
      "问题:\n",
      "学校食堂有15张桌子。每张桌子可容纳10人。通常，只有 1/10 的座位空着。通常有多少个座位？ \n",
      "答案:\n",
      "135 \n",
      "模型输出:\n",
      "学生总数：15 x 10 = 150人\n",
      "座位空着比例：1/10\n",
      "座位总数：150 x (1 - 1/10) = 150 x 9/10 = 135个座位 \n",
      "提取后的答案:\n",
      "学生总数：15 x 10 = 150人\n",
      "座位空着比例：1/10\n",
      "座位总数：150 x (1 - 1/10) = 150 x 9/10 = 135个座位\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model('./output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'prompt': [{'content': '\\n按照如下格式生成：\\n<think>\\n...\\n</think>\\n<answer>\\n...\\n</answer>\\n',\n",
    "#    'role': 'system'},\n",
    "#   {'content': '纳塔利娅在 4 月份向 48 个朋友出售了视频片段，然后在 5 月份售出了一半的视频片段。娜塔莉亚在四月和五月总共卖出了多少个视频？',\n",
    "#    'role': 'user'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import trl\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载权重\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./output/checkpoint-100/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('./output/checkpoint-100/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, prompt):\n",
    "    # prompt = \"我每天都有6块钱零花钱，那么我一周后总共有多少钱？\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\\n按照如下格式生成：\\n<think>\\n...\\n</think>\\n<answer>\\n...\\n</answer>\\n\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs, max_length=512\n",
    "    )\n",
    "\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ori = AutoModelForCausalLM.from_pretrained(\"/root/data/.cache/huggingface_hub/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775\")\n",
    "model_ori.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题:我每天有6元，一周之后还有多少钱？我忘记说了，星期一我会花一掉块钱\n",
      "微调前：```\n",
      "think\n",
      "答案：-6元\n",
      "\n",
      "think\n",
      "```\n",
      "微调后：```markdown\n",
      "<think>\n",
      "一天后剩下 \\( 6 \\times 7 = 42 \\) 元。\n",
      "星期一花掉1元，所以剩下 \\( 42 - 1 = 41 \\) 元。\n",
      "</think>\n",
      "<answer>\n",
      "41\n",
      "</answer>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"我每天有6元，一周之后还有多少钱？我忘记说了，星期一我会花一掉块钱\"\n",
    "res1, res2 = inference(model, prompt), inference(model_ori, prompt)\n",
    "\n",
    "print(f\"问题:{prompt}\")\n",
    "print(f\"微调前：{res2}\")\n",
    "print(f\"微调后：{res1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
